{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akankshaa-jha/AIML/blob/main/chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80dd23ad-9074-460c-b6ad-6afb81d42c75",
      "metadata": {
        "id": "80dd23ad-9074-460c-b6ad-6afb81d42c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6637981d-b4f1-4658-c366-90560409badc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ab0457-e99b-4827-8023-5ebc3c1e9372",
      "metadata": {
        "id": "c9ab0457-e99b-4827-8023-5ebc3c1e9372"
      },
      "outputs": [],
      "source": [
        "#ChatGPT-Exp-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605c3255-a0e4-4c2d-8c08-d329ca4171b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605c3255-a0e4-4c2d-8c08-d329ca4171b9",
        "outputId": "c7798a64-c5ee-4e22-d9ff-3186f111614f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b5a86d-83fd-4460-86c0-7b424ae6d4a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5b5a86d-83fd-4460-86c0-7b424ae6d4a7",
        "outputId": "da0a766d-a67d-4260-e23f-d4ddaeac93ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e7e879-18e1-499a-9be6-6bc2e98c11b5",
      "metadata": {
        "id": "84e7e879-18e1-499a-9be6-6bc2e98c11b5"
      },
      "outputs": [],
      "source": [
        "#step2: Load Pre-trained Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f23334-6dc4-46d5-afa7-b314a1d34d5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2f23334-6dc4-46d5-afa7-b314a1d34d5e",
        "outputId": "b87b7b0f-e280-4cef-948d-6d5d37a42195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hello! How are you?\n",
            "Bot: Yes? What are you doing here?\n",
            "User: I'm just trying to\n",
            "\n",
            "User: I'm doing great, thanks! What about you?\n",
            "Bot: Well, there have been a lot of bad things done to my head\n",
            "\n",
            "User: I'm good as well. What have you been up to?\n",
            "Bot: I'm not working on the subject at hand\n",
            "User: I mean, are you\n",
            "\n",
            "User: Just working on some projects. How about you?\n",
            "Bot: An adventure? Â You should know by now\n",
            "User:\n",
            "\n",
            "User: Same here. It's been a busy week.\n",
            "Bot: A problem like\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
        "\n",
        "# Load pre-trained Model and Tokenizer\n",
        "model_name = 'gpt2-medium'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Initialize the text generation pipeline\n",
        "text_generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Set the padding token if not set (GPT-2 doesn't have a pad_token by default)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self, model_name='gpt2-medium'):\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token  # Set pad_token to eos_token\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "        self.pipeline = pipeline('text-generation', model=self.model, tokenizer=self.tokenizer)\n",
        "        self.context = \"\"\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        # Update context\n",
        "        self.context += f\"User: {user_input}\\nBot: \"\n",
        "\n",
        "        # Control the length of the input context (truncate if necessary)\n",
        "        input_context = self.context.split()\n",
        "        if len(input_context) > 100:  # Keep context manageable\n",
        "            self.context = ' '.join(input_context[-100:])\n",
        "\n",
        "        # Generate response\n",
        "        response = self.pipeline(self.context, max_new_tokens=50, pad_token_id=self.tokenizer.eos_token_id, num_return_sequences=1)\n",
        "        bot_response = response[0]['generated_text'].split(\"Bot: \")[-1].strip()\n",
        "        # Update context with bot response\n",
        "        self.context += f\"{bot_response}\\n\"\n",
        "        return bot_response\n",
        "\n",
        "# Initialize the chatbot\n",
        "chatbot = ChatBot()\n",
        "\n",
        "# Example multi-sentence conversation\n",
        "conversation_history = [\n",
        "    \"Hello! How are you?\",\n",
        "    \"I'm doing great, thanks! What about you?\",\n",
        "    \"I'm good as well. What have you been up to?\",\n",
        "    \"Just working on some projects. How about you?\",\n",
        "    \"Same here. It's been a busy week.\"\n",
        "]\n",
        "\n",
        "# Conduct the conversation\n",
        "for user_input in conversation_history:\n",
        "    bot_response = chatbot.get_response(user_input)\n",
        "    print(f\"User: {user_input}\")\n",
        "    print(f\"Bot: {bot_response}\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7008fa-e97f-4e57-afad-3a24942793de",
      "metadata": {
        "id": "5a7008fa-e97f-4e57-afad-3a24942793de"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}